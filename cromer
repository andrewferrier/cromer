#!/usr/bin/env python3

from datetime import datetime, timedelta
from sys import platform as _platform
from subprocess import Popen, PIPE, TimeoutExpired
import argparse
import calendar
import coloredlogs
import hashlib
import json
import logging
import logging.handlers
import os
import re
import stat
import sys
import time


def parse_time_interval(time_str):
    # pylint: disable=W0142
    regex = re.compile(r'((?P<weeks>\d+?)w)?((?P<days>\d+?)d)?((?P<hours>\d+?)h)?((?P<minutes>\d+?)m)?((?P<seconds>\d+?)s)?')
    parts = regex.match(time_str)
    if not parts:
        return
    parts = parts.groupdict()
    time_params = {}
    for (name, param) in parts.items():
        if param:
            time_params[name] = int(param)
    return timedelta(**time_params)


def setup_logging(enable_syslog, verbose):
    logger = logging.getLogger('cromer')
    logger.propagate = False
    logger.setLevel(logging.DEBUG)

    if enable_syslog:
        if _platform == "linux" or _platform == "linux2":
            sysLogAddress = '/dev/log'
        elif _platform == "darwin":
            sysLogAddress = '/var/run/syslog'
        else:
            print("Unsupported platform.")
            sys.exit(3)

        syslog_handler = logging.handlers.SysLogHandler(address=sysLogAddress)
        syslog_handler.setLevel(logging.INFO)
        sysLogFormatter = logging.Formatter('%(pathname)s[%(process)d] %(levelname)s %(lineno)d %(message).1900s')
        syslog_handler.setFormatter(sysLogFormatter)
        logger.addHandler(syslog_handler)

        if verbose > 1:
            syslog_handler.setLevel(logging.DEBUG)
        elif verbose == 1:
            syslog_handler.setLevel(logging.DEBUG)
        else:
            syslog_handler.setLevel(logging.INFO)

    syserr_handler = coloredlogs.ColoredStreamHandler(stream=sys.stderr, show_timestamps=False, show_hostname=False,
                                                      show_name=False, show_severity=False)
    syserr_handler.setLevel(logging.WARNING)
    logger.addHandler(syserr_handler)

    coloredlogs.install(level=logging.DEBUG)

    if verbose > 1:
        syserr_handler.setLevel(logging.DEBUG)
    elif verbose == 1:
        syserr_handler.setLevel(logging.INFO)
    else:
        syserr_handler.setLevel(logging.WARNING)


parser = argparse.ArgumentParser()

parser.add_argument('-X', '--max-interval-between-success', dest='max_interval_between_success', type=parse_time_interval,
                    default='0s', help="The maximum interval allowed for failures before cromer will 'pass through' the "
                    "stderr information to cron, allowing it to email. Expressed like the pattern 3w2d5h7m8s. Defaults to "
                    "zero - i.e. any failure will pass through.",
                    metavar="TIME_INTERVAL")

parser.add_argument('-t', '--timeout', dest='timeout', type=parse_time_interval, default='0s',
                    help="Timeout the command after this time and consider it to have failed as if it had "
                    "produced stderr content or a non-zero return code. Parses time intervals in the same way as -X. "
                    "Defaults to infinite - no timeout.", metavar="TIME_INTERVAL")

parser.add_argument('-v', '--verbose', action='count', default=0,
                    help="Make the output more verbose. this affects both the output logged to "
                    "syslog, as well as output to the console. using this twice makes it doubly verbose. This is primarily "
                    "useful for debugging, and will break cromer as a cron wrapping tool, as it will output to stderr when "
                    "otherwise inappropriate.")

parser.add_argument('-r', '--readable-hashfile-name', dest="readable_hashfile_name", action='store_true', default=False,
                    help="Add a readable 'compressed' version of the command "
                    "plus its arguments to the hashfile name. Can have security "
                    "implications if the arguments contain sensitive "
                    "information, so defaults to off.")

parser.add_argument('-q', '--stdout-not-an-error', dest='quiet_stdout', action='store_true', default=False,
                    help="Normally stdout from the command is considered an 'error' condition also, following the Unix "
                    "principle of 'no output indicates success'. With this flag, stdout output from the command should not be "
                    "considered an error and is instead swallowed.")

parser.add_argument('-l', '--enable-syslog', dest='enable_syslog', action='store_true', default=False,
                    help="By default, cromer won't log anything to syslog, for security reasons. If you set this flag, "
                    "it will log information about the cromer job to syslog (even if the job succeeds). Also passing -v "
                    "once or twice will log even more detailed information.")

parser.add_argument('args', nargs=argparse.REMAINDER, help="The command (and arguments) you want cromer to execute for you.")

args = parser.parse_args()

setup_logging(args.enable_syslog, args.verbose)

logger = logging.getLogger('cromer')

logger.debug("Arguments are: " + str(args))

assert len(args.args) > 0

m = hashlib.md5()
for arg in args.args:
    m.update(str.encode(arg))

hashfile = os.path.join(os.path.expanduser("~"), ".cromer." + m.hexdigest() +
                        (("." + re.sub('[^0-9a-zA-Z_]+', '', ''.join(args.args))) if args.readable_hashfile_name else ''))

logger.debug("Hashfile for this command: " + hashfile)

timeout = False

my_timeout = args.timeout.total_seconds()
my_timeout = my_timeout if my_timeout > 0 else None

try:
    my_process = Popen(args.args, stdin=None, stdout=PIPE, stderr=PIPE)
    stdout, stderr = my_process.communicate(timeout=my_timeout)
    my_process.wait()
except TimeoutExpired:
    my_process.kill()
    stdout, stderr = my_process.communicate()
    logger.debug("Timeout of " + str(args.timeout) + " hit")
    timeout = True

logger.debug("Stdout is " + str(stdout))
logger.debug("Stderr is " + str(stderr))
logger.debug("Returncode is " + str(my_process.returncode))

if timeout or my_process.returncode > 0 or (not stderr == b'') or (not stdout == b'' and not args.quiet_stdout):
    command_summary_info = ("Command attempted " + ' '.join(args.args) + "\nRETURNCODE: " +
                            str(my_process.returncode) + "\nSTDOUT:\n" + str(stdout) + "\nSTDERR:\n" + str(stderr))
    if os.path.isfile(hashfile):
        if (calendar.timegm(time.gmtime()) - os.path.getmtime(hashfile)) < args.max_interval_between_success.total_seconds():
            logger.info("Still within time delta; ignoring: " + command_summary_info)
        else:
            logger.error("Max interval between success exceeded, failed:  " + command_summary_info)
            sys.exit(101)
    else:
        logger.error("Hashfile missing, failed: " + command_summary_info)
        sys.exit(102)

else:
    if args.enable_syslog:
        # It is not necessary to do this in the error cases above, because the
        # stdout information is included in command_summary_info anyway.
        logger.info("Stdout (because of always_syslog): " + str(stdout))

    logger.debug("Succeeded - writing to " + hashfile)
    jsonObject = {'stdout': str(stdout), 'stderr': str(stderr), 'returncode': my_process.returncode,
                  'lastsuccessfulrun': str(datetime.now())}
    with os.fdopen(os.open(hashfile, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR), 'w') as fp:
        json.dump(jsonObject, fp, indent=4)

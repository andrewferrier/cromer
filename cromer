#!/usr/bin/env python3

from datetime import datetime, timedelta
from subprocess import Popen, PIPE, TimeoutExpired
import argparse
import calendar
import hashlib
import importlib
import json
import logging
import logging.handlers
import os
import re
import stat
import sys
import time

import fasteners

LOCKFILE_LOCATION = '/tmp'

DELAY_ITERATIONS = 50
DELAY_STEP_LENGTH = 0.1


def parse_time_interval(time_str):
    regex = re.compile(r'((?P<weeks>\d+?)w)?((?P<days>\d+?)d)?((?P<hours>\d+?)h)?((?P<minutes>\d+?)m)?((?P<seconds>\d+?)s)?')
    parts = regex.match(time_str)
    if not parts or parts.lastindex is None:
        raise argparse.ArgumentTypeError("Time interval must be of type 3w2d5h6m7s "
                                         "(each section is optional, but one must be present)")
    parts = parts.groupdict()
    time_params = {}
    for (name, param) in parts.items():
        if param:
            time_params[name] = int(param)
    return timedelta(**time_params)


def setup_syslog_logging(logger, verbose, debug_syslog):
    if sys.platform == "linux" or sys.platform == "linux2":
        syslog_address = '/dev/log'
    elif sys.platform == "darwin":
        syslog_address = '/var/run/syslog'
    else:
        print("Unsupported platform.")
        sys.exit(3)

    if syslog_address and os.path.exists(syslog_address):
        syslog_handler = logging.handlers.SysLogHandler(address=syslog_address)
        syslog_handler.setLevel(logging.INFO)
        syslog_formatter = logging.Formatter('{pathname}[{process}] {levelname} {lineno} {message:.1900s}', style='{')
        syslog_handler.setFormatter(syslog_formatter)
        logger.addHandler(syslog_handler)

        if verbose > 0 or debug_syslog:
            syslog_handler.setLevel(logging.DEBUG)
        else:
            syslog_handler.setLevel(logging.INFO)


def setup_logging(enable_syslog, debug_syslog, verbose):
    logger = logging.getLogger('cromer')
    logger.propagate = False
    logger.setLevel(logging.DEBUG)

    if enable_syslog:
        setup_syslog_logging(logger, verbose, debug_syslog)

    syserr_handler = logging.StreamHandler(stream=sys.stderr)
    syserr_handler.setLevel(logging.WARNING)

    try:
        coloredlogs = importlib.import_module("coloredlogs")
        syserr_formatter = coloredlogs.ColoredFormatter('%(levelname)s: %(message)s')
        colored_logs_failed = False
    except ImportError:
        syserr_formatter = logging.Formatter('%(levelname)s: %(message)s')
        colored_logs_failed = True

    syserr_handler.setFormatter(syserr_formatter)
    logger.addHandler(syserr_handler)

    if verbose > 1:
        syserr_handler.setLevel(logging.DEBUG)
    elif verbose == 1:
        syserr_handler.setLevel(logging.INFO)
    else:
        syserr_handler.setLevel(logging.WARNING)

    if colored_logs_failed:
        logger.info("Couldn't set up coloredlogs")


def parse_arguments():
    parser = argparse.ArgumentParser()

    parser.add_argument('-X', '--max-interval-between-success', dest='max_interval_between_success', type=parse_time_interval,
                        default='0s', help="The maximum interval allowed for failures before cromer will 'pass through' the "
                        "stderr information to cron, allowing it to email. Expressed like the pattern 3w2d5h7m8s. Defaults to "
                        "zero - i.e. any failure will pass through.",
                        metavar="TIME_INTERVAL")

    parser.add_argument('-t', '--timeout', dest='timeout', type=parse_time_interval, default='0s',
                        help="Timeout the command after this time and consider it to have failed as if it had "
                        "produced stderr content or a non-zero return code. Parses time intervals in the same way as -X. "
                        "Defaults to infinite - no timeout.", metavar="TIME_INTERVAL")

    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help="Make the output more verbose. This affects both the output logged to syslog (if -l is also set), "
                        "as well as output to the console. Using this twice makes it doubly verbose. This is primarily useful for "
                        "debugging, and will break cromer as a cron wrapping tool, as it will output to stderr when otherwise "
                        "inappropriate.")

    parser.add_argument('-r', '--readable-hashfile-name', dest="readable_hashfile_name", action='store_true', default=False,
                        help="Add a readable 'compressed' version of the command "
                        "plus its arguments to the hashfile name. Can have security "
                        "implications if the arguments contain sensitive "
                        "information, so defaults to off.")

    parser.add_argument('-q', '--stdout-not-an-error', dest='quiet_stdout', action='store_true', default=False,
                        help="Normally stdout from the command is considered an 'error' condition also, following the Unix "
                        "principle of 'no output indicates success'. With this flag, stdout output from the command should not be "
                        "considered an error and is instead swallowed.")

    parser.add_argument('-l', '--enable-syslog', dest='enable_syslog', action='store_true', default=False,
                        help="By default, cromer won't log anything to syslog, for security reasons. If you set this flag, "
                        "it will log information about the cromer job to syslog (even if the job succeeds). Also passing -v "
                        "once or twice will log even more detailed information.")

    parser.add_argument('-d', '--debug-syslog', dest='debug_syslog', action='store_true', default=False,
                        help="This flag is the equivalent of setting '--verbose' twice, but *only* for syslog. In other words, "
                        "it will force maximum syslog output, for debugging purposes, but won't affect syserr (unless that's "
                        "otherwise affected by --verbose). Implies -l.")

    parser.add_argument('args', nargs=argparse.REMAINDER, help="The command (and arguments) you want cromer to execute for you.")

    args = parser.parse_args()

    if args.debug_syslog:
        args.enable_syslog = True

    return args


def run_process(args, my_timeout):
    timeout = False

    with Popen(args, stdin=None, stdout=PIPE, stderr=PIPE) as my_process:
        stdout = None
        stderr = None
        try:
            stdout, stderr = my_process.communicate(timeout=my_timeout)
        except TimeoutExpired:
            logger.info("Timeout of " + str(my_timeout) + " hit")
            if my_process.poll() is None:
                logger.debug("Process not completed - sending SIGTERM")
                my_process.terminate()
            delay(my_process)
            if my_process.poll() is None:
                logger.debug("Process not completed - sending SIGKILL")
                my_process.kill()
            delay(my_process)
            assert(my_process.poll() is not None)
            logger.debug("Process no longer running")
            try:
                stdout_new = my_process.stdout.read()
                stdout = stdout_new
            except ValueError:
                stdout = "Couldn't read stdout because process died, original stdout: " + str(stdout)

            try:
                stderr_new = my_process.stderr.read()
                stderr = stderr_new
            except ValueError:
                stderr = "Couldn't read stderr because process died, original stderr: " + str(stderr)

            logger.debug("Timeout of " + str(my_timeout) + " hit - after reading final streams")
            timeout = True

        return (stdout, stderr, my_process.returncode, timeout)


def delay(my_process):
    for step in range(0, DELAY_ITERATIONS):
        if my_process.poll() is not None:
            break
        time.sleep(DELAY_STEP_LENGTH)


def determine_hashfile_name(args):
    hash_calculator = hashlib.md5()
    for arg in args.args:
        hash_calculator.update(str.encode(arg))

    hashfile = os.path.join(os.path.expanduser("~"), ".cromer." + hash_calculator.hexdigest() +
                            (("." + re.sub('[^0-9a-zA-Z_]+', '', ''.join(args.args))) if args.readable_hashfile_name else ''))

    return hashfile


def determine_lockfile_name(hashfile):
    return os.path.join(LOCKFILE_LOCATION, os.path.basename(hashfile + ".lock"))


def within_success_period(hashfile):
    return (calendar.timegm(time.gmtime()) - os.path.getmtime(hashfile)) < args.max_interval_between_success.total_seconds()


def consider_executing_command(args, hashfile):
    logger = logging.getLogger('cromer')

    my_timeout = args.timeout.total_seconds()
    my_timeout = my_timeout if my_timeout > 0 else None

    (stdout, stderr, returncode, timeout) = run_process(args.args, my_timeout)

    logger.debug("Stdout is " + str(stdout))
    logger.debug("Stderr is " + str(stderr))
    logger.debug("Returncode is " + str(returncode))
    logger.debug("Command timed out: " + str(timeout))

    if timeout or returncode > 0 or stderr != b'' or (stdout != b'' and not args.quiet_stdout):
        command_summary_info = ("command attempted " + ' '.join(args.args) + "\nRETURNCODE: " +
                                str(returncode) + "\nSTDOUT:\n" + str(stdout) + "\nSTDERR:\n" + str(stderr))
        if os.path.isfile(hashfile):
            if within_success_period(hashfile):
                logger.info("Command failed or timed out; still within time delta, ignoring: " + command_summary_info)
            else:
                logger.error("Command failed or timed out; max interval between success (-X) exceeded:  " + command_summary_info)
                sys.exit(101)
        else:
            logger.error("Command failed or timed out; hashfile missing: " + command_summary_info)
            sys.exit(102)

    else:
        if args.enable_syslog:
            # It is not necessary to do this in the error cases above, because the
            # stdout information is included in command_summary_info anyway.
            logger.info("Succeeded; stdout (because of enable_syslog): " + str(stdout))

        logger.info("Succeeded - updating hashfile " + hashfile)
        jsonObject = {'stdout': str(stdout), 'stderr': str(stderr), 'returncode': returncode,
                      'lastsuccessfulrun': str(datetime.now())}
        with os.fdopen(os.open(hashfile, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR), 'w') as fp:
            json.dump(jsonObject, fp, indent=4)


args = parse_arguments()

setup_logging(args.enable_syslog, args.debug_syslog, args.verbose)

logger = logging.getLogger('cromer')

logger.debug("Arguments are: " + str(args))

if len(args.args) <= 0:
    logger.error("You must provide some arguments for cromer to run a process. Please run cromer --help for more information.")
    sys.exit(103)

hashfile = determine_hashfile_name(args)
lockfile = determine_lockfile_name(hashfile)

logger.debug("Hashfile for this command: " + hashfile)
logger.debug("Lockfile for this command: " + lockfile)

lock = fasteners.InterProcessLock(lockfile)
gotten = lock.acquire(blocking=False)
if gotten:
    logger.debug("Lock " + lockfile + " acquired.")
    consider_executing_command(args, hashfile)
    lock.release()
    logger.debug("Lock " + lockfile + " released.")
else:
    if not (os.path.isfile(hashfile) and within_success_period(hashfile)):
        logger.error("Could not get lockfile " + lockfile + "; this command is already running under cromer.")
        sys.exit(104)
    else:
        logger.debug("Could not get lockfile " + lockfile + ", but still within success period.")

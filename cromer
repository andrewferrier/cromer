#!/usr/bin/env python3

from datetime import datetime, timedelta
from subprocess import Popen, TimeoutExpired, PIPE
import argparse
import hashlib
import importlib
import json
import logging
import logging.handlers
import os
import re
import stat
import sys
import time

import fasteners

HASH_AND_LOCK_ROOT = os.path.join(os.path.expanduser("~"), ".cromer/")


def parse_time_interval(time_str):
    regex = re.compile(r'((?P<weeks>\d+?)w)?((?P<days>\d+?)d)?((?P<hours>\d+?)h)?((?P<minutes>\d+?)m)?((?P<seconds>\d+?)s)?')
    parts = regex.match(time_str)
    if not parts or parts.lastindex is None:
        raise argparse.ArgumentTypeError("Time interval must be of type 3w2d5h6m7s "
                                         "(each section is optional, but one must be present)")
    parts = parts.groupdict()
    time_params = {}
    for (name, param) in parts.items():
        if param:
            time_params[name] = int(param)
    return timedelta(**time_params)


def setup_syslog_logging(logger, verbose, debug_syslog):
    if sys.platform == "linux" or sys.platform == "linux2":
        syslog_address = '/dev/log'
    elif sys.platform == "darwin":
        syslog_address = '/var/run/syslog'
    else:
        print("Unsupported platform.")
        sys.exit(3)

    if syslog_address and os.path.exists(syslog_address):
        syslog_handler = logging.handlers.SysLogHandler(address=syslog_address)
        syslog_handler.setLevel(logging.INFO)
        syslog_formatter = logging.Formatter('{pathname}[{process}] {levelname} {lineno} {message:.1900s}', style='{')
        syslog_handler.setFormatter(syslog_formatter)
        logger.addHandler(syslog_handler)

        if verbose > 0 or debug_syslog:
            syslog_handler.setLevel(logging.DEBUG)
        else:
            syslog_handler.setLevel(logging.INFO)


def setup_logging(enable_syslog, debug_syslog, verbose):
    logger = logging.getLogger('cromer')
    logger.propagate = False
    logger.setLevel(logging.DEBUG)

    if enable_syslog:
        setup_syslog_logging(logger, verbose, debug_syslog)

    syserr_handler = logging.StreamHandler(stream=sys.stderr)
    syserr_handler.setLevel(logging.WARNING)

    try:
        coloredlogs = importlib.import_module("coloredlogs")
        syserr_formatter = coloredlogs.ColoredFormatter('%(levelname)s: %(message)s')
        colored_logs_failed = False
    except ImportError:
        syserr_formatter = logging.Formatter('%(levelname)s: %(message)s')
        colored_logs_failed = True

    syserr_handler.setFormatter(syserr_formatter)
    logger.addHandler(syserr_handler)

    if verbose > 1:
        syserr_handler.setLevel(logging.DEBUG)
    elif verbose == 1:
        syserr_handler.setLevel(logging.INFO)
    else:
        syserr_handler.setLevel(logging.WARNING)

    if colored_logs_failed:
        logger.info("Couldn't set up coloredlogs")


def parse_arguments():
    parser = argparse.ArgumentParser()

    parser.add_argument('-X', '--max-interval-between-success', dest='max_interval_between_success', type=parse_time_interval,
                        default='0s', help="The maximum interval allowed for failures before cromer will 'pass through' the "
                        "stderr information to cron, allowing it to email. Expressed like the pattern 3w2d5h7m8s. Defaults to "
                        "zero - i.e. any failure will pass through.",
                        metavar="TIME_INTERVAL")

    parser.add_argument('-t', '--timeout', dest='timeout', type=parse_time_interval, default='0s',
                        help="Timeout the command after this time and consider it to have failed as if it had "
                        "produced stderr content or a non-zero return code. Parses time intervals in the same way as -X. "
                        "Defaults to infinite - no timeout.", metavar="TIME_INTERVAL")

    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help="Make the output more verbose. This affects both the output logged to syslog (if -l is also set), "
                        "as well as output to the console. Using this twice makes it doubly verbose. This is primarily useful for "
                        "debugging, and will break cromer as a cron wrapping tool, as it will output to stderr when otherwise "
                        "inappropriate.")

    parser.add_argument('-r', '--readable-hashfile-name', dest="readable_hashfile_name", action='store_true', default=False,
                        help="Add a readable 'compressed' version of the command "
                        "plus its arguments to the hashfile name. Can have security "
                        "implications if the arguments contain sensitive "
                        "information, so defaults to off.")

    parser.add_argument('-q', '--stdout-not-an-error', dest='quiet_stdout', action='store_true', default=False,
                        help="Normally stdout from the command is considered an 'error' condition also, following the Unix "
                        "principle of 'no output indicates success'. With this flag, stdout output from the command should not be "
                        "considered an error and is instead swallowed.")

    parser.add_argument('-l', '--enable-syslog', dest='enable_syslog', action='store_true', default=False,
                        help="By default, cromer won't log anything to syslog, for security reasons. If you set this flag, "
                        "it will log information about the cromer job to syslog (even if the job succeeds). Also passing -v "
                        "once or twice will log even more detailed information.")

    parser.add_argument('-d', '--debug-syslog', dest='debug_syslog', action='store_true', default=False,
                        help="This flag is the equivalent of setting '--verbose' twice, but *only* for syslog. In other words, "
                        "it will force maximum syslog output, for debugging purposes, but won't affect syserr (unless that's "
                        "otherwise affected by --verbose). Implies -l.")

    parser.add_argument('args', nargs=argparse.REMAINDER, help="The command (and arguments) you want cromer to execute for you.")

    args = parser.parse_args()

    if args.debug_syslog:
        args.enable_syslog = True

    return args


def setup_args_and_logging():
    args = parse_arguments()

    setup_logging(args.enable_syslog, args.debug_syslog, args.verbose)

    logger = logging.getLogger('cromer')

    logger.debug("Arguments are: " + str(args))

    if len(args.args) <= 0:
        logger.error("You must provide some arguments for cromer to run a process. Please run cromer --help for more information.")
        sys.exit(103)

    return args


def run_process(args, my_timeout):
    with Popen(args, stdout=PIPE, stderr=PIPE) as process:
        try:
            stdout, stderr = process.communicate(timeout=my_timeout)
        except TimeoutExpired:
            process.kill()
            try:
                stdout, stderr = process.communicate()
                return (stdout, stderr, -1, True)
            except ValueError:
                # This is extremely confusing, but from time to time (I've observed it
                # particularly with rsync), process.communicate() just returns: ValueError:
                # Invalid file object: <_io.BufferedReader name=6>. It's not
                # clear if this happens after every TimeoutExpired, but I
                # don't think so. This method works around that by passing back
                # information to the caller to make it clear that its failed.
                #
                # This is not ideal - it appears this is probably a bug in Python.

                return ("No stdout - unexpected ValueError in run_process()",
                        "No stderr - unexpected ValueError in run_process()", -2, True)
        except:
            process.kill()
            process.wait()
            raise
        retcode = process.poll()
    return (stdout, stderr, retcode, False)


def determine_hashfile_name(args):
    hash_calculator = hashlib.md5()
    for arg in args.args:
        hash_calculator.update(str.encode(arg))

    hashfile = os.path.join(HASH_AND_LOCK_ROOT,
                            ((re.sub('[^0-9a-zA-Z_]+', '', ''.join(args.args)) + ".") if args.readable_hashfile_name else '') +
                            hash_calculator.hexdigest())

    return hashfile


def determine_lockfile_name(hashfile):
    return os.path.join(HASH_AND_LOCK_ROOT, os.path.basename(hashfile + ".lock"))


def within_success_period(args, hashfile):
    logger = logging.getLogger('cromer')

    current_time = time.time()
    hashfile_time = os.path.getmtime(hashfile)

    logger.debug("within_success_period(): Current time is " + str(current_time))
    logger.debug("within_success_period(): Time on hashfile is " + str(hashfile_time))
    return (current_time - hashfile_time) < args.max_interval_between_success.total_seconds()


def consider_executing_command(args, hashfile):
    logger = logging.getLogger('cromer')

    my_timeout = args.timeout.total_seconds()
    my_timeout = my_timeout if my_timeout > 0 else None

    (stdout, stderr, returncode, timeout) = run_process(args.args, my_timeout)

    logger.debug("Stdout is " + str(stdout))
    logger.debug("Stderr is " + str(stderr))
    logger.debug("Returncode is " + str(returncode))
    logger.debug("Command timed out: " + str(timeout))

    failed = False

    if timeout:
        failed_message = "Command timed out"
        failed = True
    elif returncode != 0:
        failed_message = "Return code greater than 0"
        failed = True
    elif stderr != b'':
        failed_message = "Command produced stderr"
        failed = True
    elif stdout != b'' and not args.quiet_stdout:
        failed_message = "Command produced stdout and -q not set"
        failed = True

    if failed:
        command_summary_info = ("\nCOMMAND ATTEMPTED: " + ' '.join(args.args) + "\nRETURNCODE: " +
                                str(returncode) + "\nSTDOUT:\n" + str(stdout) + "\nSTDERR:\n" + str(stderr))
        if os.path.isfile(hashfile):
            if within_success_period(args, hashfile):
                logger.info(failed_message + "; still within time delta, ignoring: " + command_summary_info)
            else:
                logger.error(failed_message + "; max interval between success (-X) exceeded:  " + command_summary_info)
                sys.exit(101)
        else:
            logger.error(failed_message + "; hashfile missing: " + command_summary_info)
            sys.exit(102)

    else:
        if args.enable_syslog:
            # It is not necessary to do this in the error cases above, because the
            # stdout information is included in command_summary_info anyway.
            logger.info("Succeeded; stdout (because of enable_syslog): " + str(stdout))

        logger.info("Succeeded - updating hashfile " + hashfile)
        hashfile_contents = {'stdout': str(stdout), 'stderr': str(stderr), 'returncode': returncode,
                             'lastsuccessfulrun': str(datetime.now())}
        with os.fdopen(os.open(hashfile, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR), 'w') as hashfile_fp:
            json.dump(hashfile_contents, hashfile_fp, indent=4)


def main():
    args = setup_args_and_logging()

    logger = logging.getLogger('cromer')

    hashfile = determine_hashfile_name(args)
    lockfile = determine_lockfile_name(hashfile)

    logger.info("Hashfile for this command: " + hashfile)
    logger.debug("Lockfile for this command: " + lockfile)

    lock = fasteners.InterProcessLock(lockfile)
    gotten = lock.acquire(blocking=False)
    if gotten:
        logger.debug("Lock " + lockfile + " acquired.")
        try:
            consider_executing_command(args, hashfile)
        finally:
            lock.release()
            logger.debug("Lock " + lockfile + " released.")
    else:
        if not (os.path.isfile(hashfile) and within_success_period(args, hashfile)):
            logger.error("Could not get lockfile " + lockfile + "; this command is already running under cromer.")
            sys.exit(104)
        else:
            logger.debug("Could not get lockfile " + lockfile + ", but still within success period.")

if __name__ == "__main__":
    main()

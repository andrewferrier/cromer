#!/usr/bin/env python3

import sys

if sys.version_info[0] < 3 or sys.version_info[1] < 5:
    print("This script requires a minimum Python version of 3.5.")
    sys.exit(1)

from datetime import datetime, timedelta
import argparse
import calendar
import hashlib
import importlib
import json
import logging
import logging.handlers
import os
import re
import stat
import subprocess
import time

import fasteners

HASH_AND_LOCK_ROOT = os.path.join(os.path.expanduser("~"), ".cromer/")

DELAY_ITERATIONS = 50
DELAY_STEP_LENGTH = 0.1


def parse_time_interval(time_str):
    regex = re.compile(r'((?P<weeks>\d+?)w)?((?P<days>\d+?)d)?((?P<hours>\d+?)h)?((?P<minutes>\d+?)m)?((?P<seconds>\d+?)s)?')
    parts = regex.match(time_str)
    if not parts or parts.lastindex is None:
        raise argparse.ArgumentTypeError("Time interval must be of type 3w2d5h6m7s "
                                         "(each section is optional, but one must be present)")
    parts = parts.groupdict()
    time_params = {}
    for (name, param) in parts.items():
        if param:
            time_params[name] = int(param)
    return timedelta(**time_params)


def setup_syslog_logging(logger, verbose, debug_syslog):
    if sys.platform == "linux" or sys.platform == "linux2":
        syslog_address = '/dev/log'
    elif sys.platform == "darwin":
        syslog_address = '/var/run/syslog'
    else:
        print("Unsupported platform.")
        sys.exit(3)

    if syslog_address and os.path.exists(syslog_address):
        syslog_handler = logging.handlers.SysLogHandler(address=syslog_address)
        syslog_handler.setLevel(logging.INFO)
        syslog_formatter = logging.Formatter('{pathname}[{process}] {levelname} {lineno} {message:.1900s}', style='{')
        syslog_handler.setFormatter(syslog_formatter)
        logger.addHandler(syslog_handler)

        if verbose > 0 or debug_syslog:
            syslog_handler.setLevel(logging.DEBUG)
        else:
            syslog_handler.setLevel(logging.INFO)


def setup_logging(enable_syslog, debug_syslog, verbose):
    logger = logging.getLogger('cromer')
    logger.propagate = False
    logger.setLevel(logging.DEBUG)

    if enable_syslog:
        setup_syslog_logging(logger, verbose, debug_syslog)

    syserr_handler = logging.StreamHandler(stream=sys.stderr)
    syserr_handler.setLevel(logging.WARNING)

    try:
        coloredlogs = importlib.import_module("coloredlogs")
        syserr_formatter = coloredlogs.ColoredFormatter('%(levelname)s: %(message)s')
        colored_logs_failed = False
    except ImportError:
        syserr_formatter = logging.Formatter('%(levelname)s: %(message)s')
        colored_logs_failed = True

    syserr_handler.setFormatter(syserr_formatter)
    logger.addHandler(syserr_handler)

    if verbose > 1:
        syserr_handler.setLevel(logging.DEBUG)
    elif verbose == 1:
        syserr_handler.setLevel(logging.INFO)
    else:
        syserr_handler.setLevel(logging.WARNING)

    if colored_logs_failed:
        logger.info("Couldn't set up coloredlogs")


def parse_arguments():
    parser = argparse.ArgumentParser()

    parser.add_argument('-X', '--max-interval-between-success', dest='max_interval_between_success', type=parse_time_interval,
                        default='0s', help="The maximum interval allowed for failures before cromer will 'pass through' the "
                        "stderr information to cron, allowing it to email. Expressed like the pattern 3w2d5h7m8s. Defaults to "
                        "zero - i.e. any failure will pass through.",
                        metavar="TIME_INTERVAL")

    parser.add_argument('-t', '--timeout', dest='timeout', type=parse_time_interval, default='0s',
                        help="Timeout the command after this time and consider it to have failed as if it had "
                        "produced stderr content or a non-zero return code. Parses time intervals in the same way as -X. "
                        "Defaults to infinite - no timeout.", metavar="TIME_INTERVAL")

    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help="Make the output more verbose. This affects both the output logged to syslog (if -l is also set), "
                        "as well as output to the console. Using this twice makes it doubly verbose. This is primarily useful for "
                        "debugging, and will break cromer as a cron wrapping tool, as it will output to stderr when otherwise "
                        "inappropriate.")

    parser.add_argument('-r', '--readable-hashfile-name', dest="readable_hashfile_name", action='store_true', default=False,
                        help="Add a readable 'compressed' version of the command "
                        "plus its arguments to the hashfile name. Can have security "
                        "implications if the arguments contain sensitive "
                        "information, so defaults to off.")

    parser.add_argument('-q', '--stdout-not-an-error', dest='quiet_stdout', action='store_true', default=False,
                        help="Normally stdout from the command is considered an 'error' condition also, following the Unix "
                        "principle of 'no output indicates success'. With this flag, stdout output from the command should not be "
                        "considered an error and is instead swallowed.")

    parser.add_argument('-l', '--enable-syslog', dest='enable_syslog', action='store_true', default=False,
                        help="By default, cromer won't log anything to syslog, for security reasons. If you set this flag, "
                        "it will log information about the cromer job to syslog (even if the job succeeds). Also passing -v "
                        "once or twice will log even more detailed information.")

    parser.add_argument('-d', '--debug-syslog', dest='debug_syslog', action='store_true', default=False,
                        help="This flag is the equivalent of setting '--verbose' twice, but *only* for syslog. In other words, "
                        "it will force maximum syslog output, for debugging purposes, but won't affect syserr (unless that's "
                        "otherwise affected by --verbose). Implies -l.")

    parser.add_argument('args', nargs=argparse.REMAINDER, help="The command (and arguments) you want cromer to execute for you.")

    args = parser.parse_args()

    if args.debug_syslog:
        args.enable_syslog = True

    return args


def run_process(args, my_timeout):
    try:
        completed_process = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=my_timeout)
        return (completed_process.stdout, completed_process.stderr, completed_process.returncode, False)
    except subprocess.TimeoutExpired as timeout:
        return (timeout.stdout, timeout.stderr, -1, True)
    except ValueError as error:
        # This is extremely confusing, but from time to time (I've observed it
        # particularly with rsync), subprocess.run just returns: ValueError:
        # Invalid file object: <_io.BufferedReader name=6>
        #
        # This appears to only be in circumstances where it has timed
        # out/failed. Therefore, this method works around that by passing back
        # information to the caller to make it clear that its failed.
        #
        # This is not ideal - it appears this is probably a bug in Python.

        return ("No stdout - unexpected ValueError in run_process()", "No stdout - unexpected ValueError in run_process()", -2, True)


def determine_hashfile_name(args):
    hash_calculator = hashlib.md5()
    for arg in args.args:
        hash_calculator.update(str.encode(arg))

    hashfile = os.path.join(HASH_AND_LOCK_ROOT, hash_calculator.hexdigest() +
                            (("." + re.sub('[^0-9a-zA-Z_]+', '', ''.join(args.args))) if args.readable_hashfile_name else ''))

    return hashfile


def determine_lockfile_name(hashfile):
    return os.path.join(HASH_AND_LOCK_ROOT, os.path.basename(hashfile + ".lock"))


def within_success_period(hashfile):
    return (calendar.timegm(time.gmtime()) - os.path.getmtime(hashfile)) < args.max_interval_between_success.total_seconds()


def consider_executing_command(args, hashfile):
    logger = logging.getLogger('cromer')

    my_timeout = args.timeout.total_seconds()
    my_timeout = my_timeout if my_timeout > 0 else None

    (stdout, stderr, returncode, timeout) = run_process(args.args, my_timeout)

    logger.debug("Stdout is " + str(stdout))
    logger.debug("Stderr is " + str(stderr))
    logger.debug("Returncode is " + str(returncode))
    logger.debug("Command timed out: " + str(timeout))

    if timeout or returncode > 0 or stderr != b'' or (stdout != b'' and not args.quiet_stdout):
        command_summary_info = ("command attempted " + ' '.join(args.args) + "\nRETURNCODE: " +
                                str(returncode) + "\nSTDOUT:\n" + str(stdout) + "\nSTDERR:\n" + str(stderr))
        if os.path.isfile(hashfile):
            if within_success_period(hashfile):
                logger.info("Command failed or timed out; still within time delta, ignoring: " + command_summary_info)
            else:
                logger.error("Command failed or timed out; max interval between success (-X) exceeded:  " + command_summary_info)
                sys.exit(101)
        else:
            logger.error("Command failed or timed out; hashfile missing: " + command_summary_info)
            sys.exit(102)

    else:
        if args.enable_syslog:
            # It is not necessary to do this in the error cases above, because the
            # stdout information is included in command_summary_info anyway.
            logger.info("Succeeded; stdout (because of enable_syslog): " + str(stdout))

        logger.info("Succeeded - updating hashfile " + hashfile)
        jsonObject = {'stdout': str(stdout), 'stderr': str(stderr), 'returncode': returncode,
                      'lastsuccessfulrun': str(datetime.now())}
        with os.fdopen(os.open(hashfile, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR), 'w') as fp:
            json.dump(jsonObject, fp, indent=4)


args = parse_arguments()

setup_logging(args.enable_syslog, args.debug_syslog, args.verbose)

logger = logging.getLogger('cromer')

logger.debug("Arguments are: " + str(args))

if len(args.args) <= 0:
    logger.error("You must provide some arguments for cromer to run a process. Please run cromer --help for more information.")
    sys.exit(103)

hashfile = determine_hashfile_name(args)
lockfile = determine_lockfile_name(hashfile)

logger.debug("Hashfile for this command: " + hashfile)
logger.debug("Lockfile for this command: " + lockfile)

lock = fasteners.InterProcessLock(lockfile)
gotten = lock.acquire(blocking=False)
if gotten:
    logger.debug("Lock " + lockfile + " acquired.")
    consider_executing_command(args, hashfile)
    lock.release()
    logger.debug("Lock " + lockfile + " released.")
else:
    if not (os.path.isfile(hashfile) and within_success_period(hashfile)):
        logger.error("Could not get lockfile " + lockfile + "; this command is already running under cromer.")
        sys.exit(104)
    else:
        logger.debug("Could not get lockfile " + lockfile + ", but still within success period.")

#!/usr/bin/env python3

from datetime import datetime, timedelta
from subprocess import Popen, PIPE, TimeoutExpired
import argparse
import calendar
import hashlib
import importlib
import json
import logging
import logging.handlers
import os
import re
import stat
import sys
import time


def parse_time_interval(time_str):
    regex = re.compile(r'((?P<weeks>\d+?)w)?((?P<days>\d+?)d)?((?P<hours>\d+?)h)?((?P<minutes>\d+?)m)?((?P<seconds>\d+?)s)?')
    parts = regex.match(time_str)
    if not parts or parts.lastindex is None:
        raise argparse.ArgumentTypeError("Time interval must be of type 3w2d5h6m7s "
                                         "(each section is optional, but one must be present)")
    parts = parts.groupdict()
    time_params = {}
    for (name, param) in parts.items():
        if param:
            time_params[name] = int(param)
    return timedelta(**time_params)


def setup_syslog_logging(logger, verbose):
    if sys.platform == "linux" or sys.platform == "linux2":
        syslog_address = '/dev/log'
    elif sys.platform == "darwin":
        syslog_address = '/var/run/syslog'
    else:
        print("Unsupported platform.")
        sys.exit(3)

    if syslog_address and os.path.exists(syslog_address):
        syslog_handler = logging.handlers.SysLogHandler(address=syslog_address)
        syslog_handler.setLevel(logging.INFO)
        syslog_formatter = logging.Formatter('{pathname}[{process}] {levelname} {lineno} {message:.1900s}', style='{')
        syslog_handler.setFormatter(syslog_formatter)
        logger.addHandler(syslog_handler)

        if verbose > 0:
            syslog_handler.setLevel(logging.DEBUG)
        else:
            syslog_handler.setLevel(logging.INFO)


def setup_logging(enable_syslog, verbose):
    logger = logging.getLogger('cromer')
    logger.propagate = False
    logger.setLevel(logging.DEBUG)

    if enable_syslog:
        setup_syslog_logging(logger, verbose)

    syserr_handler = logging.StreamHandler(stream=sys.stderr)
    syserr_handler.setLevel(logging.WARNING)

    try:
        coloredlogs = importlib.import_module("coloredlogs")
        syserr_formatter = coloredlogs.ColoredFormatter('%(levelname)s: %(message)s')
        colored_logs_failed = False
    except ImportError:
        syserr_formatter = logging.Formatter('%(levelname)s: %(message)s')
        colored_logs_failed = True

    syserr_handler.setFormatter(syserr_formatter)
    logger.addHandler(syserr_handler)

    if verbose > 1:
        syserr_handler.setLevel(logging.DEBUG)
    elif verbose == 1:
        syserr_handler.setLevel(logging.INFO)
    else:
        syserr_handler.setLevel(logging.WARNING)

    if colored_logs_failed:
        logger.info("Couldn't set up coloredlogs")


def parse_arguments():
    parser = argparse.ArgumentParser()

    parser.add_argument('-X', '--max-interval-between-success', dest='max_interval_between_success', type=parse_time_interval,
                        default='0s', help="The maximum interval allowed for failures before cromer will 'pass through' the "
                        "stderr information to cron, allowing it to email. Expressed like the pattern 3w2d5h7m8s. Defaults to "
                        "zero - i.e. any failure will pass through.",
                        metavar="TIME_INTERVAL")

    parser.add_argument('-t', '--timeout', dest='timeout', type=parse_time_interval, default='0s',
                        help="Timeout the command after this time and consider it to have failed as if it had "
                        "produced stderr content or a non-zero return code. Parses time intervals in the same way as -X. "
                        "Defaults to infinite - no timeout.", metavar="TIME_INTERVAL")

    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help="Make the output more verbose. This affects both the output logged to "
                        "syslog, as well as output to the console. using this twice makes it doubly verbose. This is primarily "
                        "useful for debugging, and will break cromer as a cron wrapping tool, as it will output to stderr when "
                        "otherwise inappropriate.")

    parser.add_argument('-r', '--readable-hashfile-name', dest="readable_hashfile_name", action='store_true', default=False,
                        help="Add a readable 'compressed' version of the command "
                        "plus its arguments to the hashfile name. Can have security "
                        "implications if the arguments contain sensitive "
                        "information, so defaults to off.")

    parser.add_argument('-q', '--stdout-not-an-error', dest='quiet_stdout', action='store_true', default=False,
                        help="Normally stdout from the command is considered an 'error' condition also, following the Unix "
                        "principle of 'no output indicates success'. With this flag, stdout output from the command should not be "
                        "considered an error and is instead swallowed.")

    parser.add_argument('-l', '--enable-syslog', dest='enable_syslog', action='store_true', default=False,
                        help="By default, cromer won't log anything to syslog, for security reasons. If you set this flag, "
                        "it will log information about the cromer job to syslog (even if the job succeeds). Also passing -v "
                        "once or twice will log even more detailed information.")

    parser.add_argument('args', nargs=argparse.REMAINDER, help="The command (and arguments) you want cromer to execute for you.")

    args = parser.parse_args()

    return args


def run_process(args, my_timeout):
    timeout = False

    with Popen(args, stdin=None, stdout=PIPE, stderr=PIPE) as my_process:
        stdout = None
        stderr = None
        try:
            stdout, stderr = my_process.communicate(timeout=my_timeout)
            my_process.wait()
        except TimeoutExpired:
            try:
                stdout_new = my_process.stdout.read()
                stdout = stdout_new
            except ValueError:
                stdout = "Couldn't read stdout because process died, original stdout: " + str(stdout)

            try:
                stderr_new = my_process.stderr.read()
                stderr = stderr_new
            except ValueError:
                stderr = "Couldn't read stderr because process died, original stderr: " + str(stderr)

            logger.info("Timeout of " + str(my_timeout) + " hit")
            timeout = True
            my_process.kill()

        return (stdout, stderr, my_process.returncode, timeout)


def determine_hashfile_name(args):
    hash_calculator = hashlib.md5()
    for arg in args.args:
        hash_calculator.update(str.encode(arg))

    hashfile = os.path.join(os.path.expanduser("~"), ".cromer." + hash_calculator.hexdigest() +
                            (("." + re.sub('[^0-9a-zA-Z_]+', '', ''.join(args.args))) if args.readable_hashfile_name else ''))

    return hashfile


args = parse_arguments()

setup_logging(args.enable_syslog, args.verbose)

logger = logging.getLogger('cromer')

logger.debug("Arguments are: " + str(args))

if len(args.args) <= 0:
    logger.error("You must provide some arguments for cromer to run a process. Please run cromer --help for more information.")
    sys.exit(103)

hashfile = determine_hashfile_name(args)

logger.debug("Hashfile for this command: " + hashfile)

my_timeout = args.timeout.total_seconds()
my_timeout = my_timeout if my_timeout > 0 else None

(stdout, stderr, returncode, timeout) = run_process(args.args, my_timeout)

logger.debug("Stdout is " + str(stdout))
logger.debug("Stderr is " + str(stderr))
logger.debug("Returncode is " + str(returncode))

if timeout or returncode > 0 or stderr != b'' or (stdout != b'' and not args.quiet_stdout):
    command_summary_info = ("command attempted " + ' '.join(args.args) + "\nRETURNCODE: " +
                            str(returncode) + "\nSTDOUT:\n" + str(stdout) + "\nSTDERR:\n" + str(stderr))
    if os.path.isfile(hashfile):
        if (calendar.timegm(time.gmtime()) - os.path.getmtime(hashfile)) < args.max_interval_between_success.total_seconds():
            logger.info("Failed; still within time delta, ignoring: " + command_summary_info)
        else:
            logger.error("Failed; max interval between success (-X) exceeded:  " + command_summary_info)
            sys.exit(101)
    else:
        logger.error("Failed; hashfile missing: " + command_summary_info)
        sys.exit(102)

else:
    if args.enable_syslog:
        # It is not necessary to do this in the error cases above, because the
        # stdout information is included in command_summary_info anyway.
        logger.info("Succeeded; stdout (because of always_syslog): " + str(stdout))

    logger.debug("Succeeded - writing to " + hashfile)
    jsonObject = {'stdout': str(stdout), 'stderr': str(stderr), 'returncode': returncode,
                  'lastsuccessfulrun': str(datetime.now())}
    with os.fdopen(os.open(hashfile, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, stat.S_IRUSR | stat.S_IWUSR), 'w') as fp:
        json.dump(jsonObject, fp, indent=4)
